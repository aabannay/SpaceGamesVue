{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4910,"status":"ok","timestamp":1744133531832,"user":{"displayName":"Osamah 1995","userId":"07866273701012002264"},"user_tz":-180},"id":"E2eiqecuhncR"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import torch\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"bNYOEA3Nh8ac"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/hub.py:330: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n","  warnings.warn(\n","Downloading: \"https://github.com/intel-isl/MiDaS/zipball/master\" to /root/.cache/torch/hub/master.zip\n","/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n","  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n","Downloading: \"https://github.com/isl-org/MiDaS/releases/download/v3/dpt_large_384.pt\" to /root/.cache/torch/hub/checkpoints/dpt_large_384.pt\n","100%|██████████| 1.28G/1.28G [00:15\u003c00:00, 86.2MB/s]\n","Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"]}],"source":["# Choose model type: \"DPT_Large\" (more accurate) or \"MiDaS_small\" (faster)\n","model_type = \"DPT_Large\"\n","\n","# Load the MiDaS model from PyTorch Hub\n","midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","midas.to(device)\n","midas.eval()\n","\n","# Load the appropriate transforms for the chosen model\n","midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n","if model_type in [\"DPT_Large\", \"DPT_Hybrid\"]:\n","    transform = midas_transforms.dpt_transform\n","else:\n","    transform = midas_transforms.small_transform\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hb3IREP_igam"},"outputs":[],"source":["# Define maximum disparity (pixel shift) for closest objects\n","max_disp = 20\n","\n","# Open the input video\n","input_video = \"input.mp4\"\n","cap = cv2.VideoCapture(input_video)\n","if not cap.isOpened():\n","    raise ValueError(\"Error opening video file\")\n","\n","# Retrieve video properties\n","fps = cap.get(cv2.CAP_PROP_FPS)\n","width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","# Prepare a VideoWriter for the output (side-by-side) video\n","output_video = \"output_stereo.mp4\"\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","# Output width is doubled (left + right view)\n","out = cv2.VideoWriter(output_video, fourcc, fps, (width * 2, height))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":117324,"status":"ok","timestamp":1741856291705,"user":{"displayName":"Osamah 1995","userId":"07866273701012002264"},"user_tz":-180},"id":"3fOQX8BYjVu8","outputId":"e85deae4-7fc6-4d3e-ac00-9c5e39e4f78f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing 1238 frames...\n","\n","Stereoscopic conversion complete!\n"]}],"source":["frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","print(f\"Processing {frame_count} frames...\")\n","\n","frame_index = 0\n","while True:\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # Convert the frame from BGR to RGB\n","    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","    # Preprocess image and move to GPU\n","    input_batch = transform(img_rgb).to(device)\n","\n","    # Estimate depth with the MiDaS model\n","    with torch.no_grad():\n","        prediction = midas(input_batch)\n","\n","    # Resize depth prediction to original frame dimensions\n","    prediction_resized = torch.nn.functional.interpolate(\n","        prediction.unsqueeze(1),\n","        size=(height, width),\n","        mode=\"bicubic\",\n","        align_corners=False\n","    ).squeeze().cpu().numpy()\n","\n","    # Normalize the depth map to range [0, 1]\n","    depth_min = prediction_resized.min()\n","    depth_max = prediction_resized.max()\n","    normalized_depth = (prediction_resized - depth_min) / (depth_max - depth_min + 1e-8)\n","\n","    # Compute disparity: closer objects (lower depth) get a higher disparity.\n","    # We use (1 - normalized_depth) so that nearer objects have larger disparity.\n","    disparity = max_disp * (1 - normalized_depth)\n","    disparity = disparity.astype(np.float32)\n","\n","    # Create a meshgrid for pixel coordinates\n","    xx, yy = np.meshgrid(np.arange(width), np.arange(height))\n","    # For the right view, shift pixels horizontally by subtracting the disparity\n","    # (simulating the perspective of a right-offset camera)\n","    map_x = (xx - disparity).astype(np.float32)\n","    map_y = yy.astype(np.float32)\n","\n","    # Warp the original frame to generate the right view using the computed mapping\n","    right_view = cv2.remap(frame, map_x, map_y, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)\n","\n","    # Concatenate the original frame (left view) and the warped frame (right view) side-by-side\n","    stereo_frame = np.concatenate((frame, right_view), axis=1)\n","\n","    # Write the stereoscopic frame to the output video\n","    out.write(stereo_frame)\n","\n","    frame_index += 1\n","    if frame_index % 10 == 0:\n","        print(f\"Processed {frame_index}/{frame_count} frames\", end='\\r')\n","\n","cap.release()\n","out.release()\n","print(\"\\nStereoscopic conversion complete!\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMhGLweBKrfB1EEdQueKWBS","gpuType":"A100","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}